# -*- coding: utf-8 -*-
"""Homework5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A7wfgN7bB-TUAWeAyLAPg4J4sKfIv6FL
"""

# Data Poisoning Simulation (Q4) - TensorFlow IMDB Classifier
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Load IMDB dataset
def load_and_preprocess():
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=5000)
    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=500)
    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=500)
    return (x_train, y_train), (x_test, y_test)

# Poison the training data
def poison_labels(x_train, y_train):
    np.random.seed(42)
    poison_indices = np.random.choice(len(x_train), size=500, replace=False)
    for idx in poison_indices:
        y_train[idx] = 1 - y_train[idx]  # flip label
    return x_train, y_train

# Build sentiment classifier
def build_model():
    model = models.Sequential([
        layers.Embedding(5000, 32, input_length=500),
        layers.Flatten(),
        layers.Dense(250, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Plot accuracy comparison
def plot_accuracy(history_clean, history_poisoned):
    plt.figure(figsize=(8, 5))
    plt.plot(history_clean.history['val_accuracy'], label='Clean Validation Accuracy')
    plt.plot(history_poisoned.history['val_accuracy'], label='Poisoned Validation Accuracy')
    plt.title('Effect of Data Poisoning on Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.savefig("accuracy_comparison.png")
    plt.close()

# Plot confusion matrices
def plot_confusion_matrices(model_clean, model_poisoned, x_test, y_test):
    y_pred_clean = (model_clean.predict(x_test) > 0.5).astype("int32")
    y_pred_poisoned = (model_poisoned.predict(x_test) > 0.5).astype("int32")

    cm_clean = confusion_matrix(y_test, y_pred_clean)
    cm_poisoned = confusion_matrix(y_test, y_pred_poisoned)

    disp_clean = ConfusionMatrixDisplay(confusion_matrix=cm_clean, display_labels=["Neg", "Pos"])
    disp_poisoned = ConfusionMatrixDisplay(confusion_matrix=cm_poisoned, display_labels=["Neg", "Pos"])

    disp_clean.plot()
    plt.title("Confusion Matrix - Clean Model")
    plt.savefig("confusion_matrix_clean.png")
    plt.close()

    disp_poisoned.plot()
    plt.title("Confusion Matrix - Poisoned Model")
    plt.savefig("confusion_matrix_poisoned.png")
    plt.close()

# Run the training and comparison
if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = load_and_preprocess()

    # Train on clean data
    model_clean = build_model()
    print("Training on clean data...")
    history_clean = model_clean.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=64)

    # Poison data and retrain
    x_train_poisoned, y_train_poisoned = poison_labels(x_train.copy(), y_train.copy())
    model_poisoned = build_model()
    print("Training on poisoned data...")
    history_poisoned = model_poisoned.fit(x_train_poisoned, y_train_poisoned, validation_data=(x_test, y_test), epochs=2, batch_size=64)

    # Compare performance
    print("Clean Validation Accuracy:", history_clean.history['val_accuracy'])
    print("Poisoned Validation Accuracy:", history_poisoned.history['val_accuracy'])

    # Plot results
    plot_accuracy(history_clean, history_poisoned)
    plot_confusion_matrices(model_clean, model_poisoned, x_test, y_test)