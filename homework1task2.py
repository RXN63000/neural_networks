# -*- coding: utf-8 -*-
"""homework1task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PBvvUxaxv3JOkm_IOORUSllMvUmKdhHy
"""

#Loss Functions & Hyperparameter Tuning

import tensorflow as tf
import matplotlib.pyplot as plt

# 1. Define true values (y_true) and model predictions (y_pred)
y_true = tf.constant([1, 2, 3, 4, 5])
y_pred = tf.constant([2, 3, 4, 5, 6])

# 2. Compute Mean Squared Error (MSE) and Categorical Cross-Entropy (CCE) losses
mse_loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
cce_loss = tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred)  # Note: CCE may require one-hot encoding for y_true

# Print loss values
print(f"MSE Loss: {mse_loss.numpy()}")
print(f"Cross-Entropy Loss: {cce_loss.numpy()}")

# Modify predictions slightly and check how loss values change
y_pred_modified = tf.constant([1.5, 2.5, 3.5, 4.5, 5.5])
mse_loss_modified = tf.keras.losses.MeanSquaredError()(y_true, y_pred_modified)
cce_loss_modified = tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred_modified)  # Note: CCE may require one-hot encoding for y_true

# Print modified loss values
print(f"Modified MSE Loss: {mse_loss_modified.numpy()}")
print(f"Modified Cross-Entropy Loss: {cce_loss_modified.numpy()}")

# 3. Create a bar chart comparing MSE and Cross-Entropy Loss
loss_values = [mse_loss.numpy(), cce_loss.numpy()]
loss_names = ['MSE', 'Cross-Entropy']

plt.figure(figsize=(8, 6))
plt.bar(loss_names, loss_values, color=['blue', 'orange'])
plt.title('Comparison of Loss Functions')
plt.xlabel('Loss Function')
plt.ylabel('Loss Value')
plt.grid(axis='y')  # Add grid only to the y-axis
plt.show()